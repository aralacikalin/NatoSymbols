{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "-vFwLwoHoPBR"
   ],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, Reshape, Flatten, Dense, Lambda\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.losses import mse\n",
    "\n",
    "from sklearn import metrics as sklearn_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "from google.colab import drive\n",
    "\n",
    "import shutil"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "6jVkALCs40Wb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir /content/images\n",
    "!mkdir /content/images/test\n",
    "!mkdir /content/labels\n",
    "!mkdir /content/labels/test\n",
    "!mkdir /content/extra_labels\n",
    "!mkdir /content/extra_labels/test\n",
    "!mkdir /content/rotations\n",
    "!mkdir /content/rotations/test"
   ],
   "metadata": {
    "id": "Wv6OV1_N3Yxs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip -q '/content/drive/My Drive/NATO/test6.zip' -d '/content/images/test'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test6l.zip' -d '/content/labels/test'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test6el.zip' -d '/content/extra_labels/test'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test6r.zip' -d '/content/rotations/test'"
   ],
   "metadata": {
    "id": "KWn54G_x3c1G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model"
   ],
   "metadata": {
    "id": "NPt6Z4LmoS9s"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def Sampling(inputs):\n",
    "    mean, log_var = inputs\n",
    "    return K.random_normal(tf.shape(mean)) * K.exp(log_var / 2) + mean \n",
    "    \n",
    "def model_version12():\n",
    "    # autoencoder model\n",
    "    beta_value = 50\n",
    "    # encoder\n",
    "    input = Input(shape=(80, 80, 1))\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(input)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    codings_mean = keras.layers.Dense(10, name=\"encoder_mean\")(x)\n",
    "    codings_log_var = keras.layers.Dense(10, name=\"encoder_log_var\")(x)\n",
    "    codings = Lambda(Sampling, name=\"encoder_output\")([codings_mean, codings_log_var])\n",
    "    variational_encoder = keras.models.Model(inputs=[input], outputs=[codings_mean, codings_log_var, codings], name=\"encoder\")\n",
    "\n",
    "    #decoder\n",
    "    decoder_inputs = keras.layers.Input(shape=(10))\n",
    "    z = Dense(256, activation='relu')(decoder_inputs)\n",
    "    z = Dense(256, activation='relu')(z)\n",
    "    z = Dense(5*5*32, activation='relu')(z)\n",
    "    z = Reshape((5, 5, 32))(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    output = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(z)\n",
    "    variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[output], name=\"decoder\")\n",
    "\n",
    "    _, _, codings = variational_encoder(input)\n",
    "    reconstructions = variational_decoder(codings)\n",
    "    variational_ae = keras.models.Model(inputs=[input], outputs=[reconstructions], name=\"autoencoder\")\n",
    "\n",
    "    reconstruction_loss_factor = 1000\n",
    "    reconstruction_loss = mse(K.flatten(input), K.flatten(reconstructions))\n",
    "    reconstruction_loss *= 80 * 80 * 1\n",
    "    kl_loss = -0.5 * beta_value * K.sum(1 + codings_log_var - K.square(codings_mean) - K.exp(codings_log_var), axis=1) \n",
    "    vae_loss = K.mean(reconstruction_loss_factor * reconstruction_loss + kl_loss)\n",
    "    variational_ae.add_loss(vae_loss)\n",
    "\n",
    "    variational_ae.add_metric(kl_loss, name=\"kl_loss\")\n",
    "    variational_ae.add_metric(reconstruction_loss, name=\"reconstruction_loss\")\n",
    "\n",
    "    return variational_ae"
   ],
   "metadata": {
    "id": "pihaGxaeMRzH"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Dict = {0: 'advance_to_contact', 2: 'attack', 9: 'counterattack', 18: 'main_attack'}\n",
    "Dict2 = {0: 'otse_k', 1: 'otse_l', 2: 'parem_n', 3: 'parem_y', 4: 'vasak_n', 5: 'vasak_y'}\n",
    "Dict3 = {\"otse_l\": 0, \"otse_k\": 1, \"parem_n\": 2, \"parem_y\": 3, \"vasak_n\": 4, \"vasak_y\": 5}"
   ],
   "metadata": {
    "id": "p4q61Yz-3l3h"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "images_test = '/content/images/test'\n",
    "labels_test = '/content/labels/test'\n",
    "extra_labels_test = '/content/extra_labels/test'\n",
    "rotations_test = '/content/rotations/test'\n",
    "\n",
    "file_list = os.listdir(images_test)\n",
    "model = model_version12()\n",
    "model2 = model_version12()\n",
    "model3 = model_version12()\n",
    "model4 = model_version12()\n",
    "\n",
    "actual = []\n",
    "liPredicted = []\n",
    "\n",
    "symbolType = \"advance_to_contact\"\n",
    "\n",
    "model.load_weights('/content/drive/MyDrive/models_trajectory_final/advance_to_contact_autoencoder_model12_b50_10.h5')\n",
    "encoder_atc = Model(inputs=model.input, outputs=model.get_layer(\"encoder\").output)\n",
    "\n",
    "model2.load_weights('/content/drive/MyDrive/models_trajectory_final/attack_autoencoder_model12_b50_10.h5')\n",
    "encoder_a = Model(inputs=model2.input, outputs=model2.get_layer(\"encoder\").output)\n",
    "\n",
    "model3.load_weights('/content/drive/MyDrive/models_trajectory_final/counterattack_autoencoder_model12_b50_10.h5')\n",
    "encoder_ca = Model(inputs=model3.input, outputs=model3.get_layer(\"encoder\").output)\n",
    "\n",
    "model4.load_weights('/content/drive/MyDrive/models_trajectory_final/main_attack_autoencoder_model12_b50_10.h5')\n",
    "encoder_ma = Model(inputs=model4.input, outputs=model4.get_layer(\"encoder\").output)\n",
    "\n",
    "for name in tqdm(file_list):\n",
    "    image = cv2.imread(images_test+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
    "    imageW = image.shape[1]\n",
    "    imageH = image.shape[0]\n",
    "    with open(labels_test+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        lines = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "    with open(extra_labels_test+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        lines_extra = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "    with open(rotations_test+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        rotations = [line.rstrip('\\n') for line in f]\n",
    "\n",
    "        for i, line in enumerate(lines):\n",
    "            cls = int(line.split(\" \")[0])\n",
    "            # if Dict[cls] == symbolType:\n",
    "            \n",
    "            x = int(((float(line.split(\" \")[1])-(float(line.split(\" \")[3])/2)) * imageW) - 5)\n",
    "            y = int(((float(line.split(\" \")[2])-(float(line.split(\" \")[4])/2)) * imageH) - 5)\n",
    "            w = int((float(line.split(\" \")[3]) * imageW) + 5)\n",
    "            h = int((float(line.split(\" \")[4]) * imageH) + 5)\n",
    "\n",
    "            # Symbol\n",
    "            crop_image = image[y:y+h, x:x+w]\n",
    "            img_rotated = ndimage.rotate(crop_image, -int(rotations[i]), mode='constant', cval=255)\n",
    "            dim = (80, 80)\n",
    "            resized_img = cv2.resize(img_rotated, dim, interpolation = cv2.INTER_AREA)\n",
    "            binImg = img = np.where(resized_img <= 150, 0, 255)\n",
    "\n",
    "            ## Predict\n",
    "            formatImage = np.array([binImg])\n",
    "            formatImage = formatImage.astype('float32') / 255.\n",
    "            formatImage = formatImage.reshape(formatImage.shape[0], formatImage.shape[1], formatImage.shape[2], 1)\n",
    "\n",
    "            if Dict[cls] == \"advance_to_contact\":\n",
    "                _, _, predicted = encoder_atc.predict(formatImage, verbose = 0)\n",
    "            elif Dict[cls] == \"attack\":\n",
    "                _, _, predicted = encoder_a.predict(formatImage, verbose = 0)\n",
    "            elif Dict[cls] == \"counterattack\":\n",
    "                _, _, predicted = encoder_ca.predict(formatImage, verbose = 0)\n",
    "            elif Dict[cls] == \"main_attack\":\n",
    "                _, _, predicted = encoder_ma.predict(formatImage, verbose = 0)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "            dataLoad = np.load(\"/content/drive/MyDrive/npy_final/\"+Dict[cls]+\"_data_model12_b50_10.npy\", allow_pickle=True)\n",
    "\n",
    "            load_features = dataLoad.item().get(\"features\")\n",
    "            load_images = dataLoad.item().get(\"images\")\n",
    "            load_extra_class = dataLoad.item().get(\"extra_label\")\n",
    "            features_reshape = load_features.reshape((-1, np.prod((load_features.shape[1:]))))\n",
    "\n",
    "            knn_cosine = NearestNeighbors(n_neighbors=1, metric=\"cosine\")\n",
    "            knn_cosine.fit(features_reshape)\n",
    "\n",
    "            actual.append(int(lines_extra[i]))\n",
    "\n",
    "            predicted_reshape = predicted.reshape((-1, np.prod((predicted.shape[1:]))))\n",
    "            _, indices = knn_cosine.kneighbors([predicted_reshape[0]])\n",
    "            result = [load_extra_class[idx] for idx in indices.flatten()]\n",
    "            result_img = [load_images[idx] for idx in indices.flatten()]\n",
    "            liPredicted.append(Dict3[result[0]])"
   ],
   "metadata": {
    "id": "_eFkzAwz3nfA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "confusion_matrix = sklearn_metrics.confusion_matrix(actual, liPredicted)\n",
    "cm_display = sklearn_metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['wide s.', 'narrow s.', '45째 right', '90째 right', '45째 left', '90째 left'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "cm_display.plot(ax = ax, xticks_rotation = 45)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(actual, liPredicted))"
   ],
   "metadata": {
    "id": "YVpjXRkf3oz1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}