{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTnmQn7n8xvy"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Reshape, UpSampling2D\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from imutils import build_montages\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir /content/images\n",
    "!mkdir /content/images/train\n",
    "!mkdir /content/images/test\n",
    "!mkdir /content/labels\n",
    "!mkdir /content/labels/train\n",
    "!mkdir /content/labels/test"
   ],
   "metadata": {
    "id": "VOXBB-8MJPDJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip -q '/content/drive/My Drive/NATO/train.zip' -d '/content/images/train'\n",
    "!unzip -q '/content/drive/My Drive/NATO/train_l.zip' -d '/content/labels/train'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test.zip' -d '/content/images/test'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test_l.zip' -d '/content/labels/test'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNtsv2P_j9iT",
    "outputId": "1b35ec1f-b969-4bf8-a36c-9dfb6a5bfabb",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Dict = {0: 'advance_to_contact', 2: 'attack', 9: 'counterattack', 18: 'main_attack'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Dict_images = {key: [] for key in Dict.values()}\n",
    "Dict_images_test = {key: [] for key in Dict.values()}"
   ],
   "metadata": {
    "id": "J47qILT4j7m7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "images = '/content/images/train'\n",
    "labels = '/content/labels/train'\n",
    "\n",
    "file_list = os.listdir(images)\n",
    "\n",
    "for name in tqdm(file_list):\n",
    "    tmp_list_class = []\n",
    "    image = cv2.imread(images+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
    "    with open(labels+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        lines = [line.rstrip('\\n') for line in f]\n",
    "        for line in lines:\n",
    "            x = int((float(line.split(\" \")[1])-(float(line.split(\" \")[3])/2)) * 770)\n",
    "            y = int((float(line.split(\" \")[2])-(float(line.split(\" \")[4])/2)) * 576)\n",
    "            w = int(float(line.split(\" \")[3]) * 770 + 5)\n",
    "            h = int(float(line.split(\" \")[4]) * 576 + 5)\n",
    "\n",
    "            crop_image = image[y:y+h, x:x+w]\n",
    "            tmp_list_class.append(int(line.split(\" \")[0]))\n",
    "            dim = (120, 120)\n",
    "            resized_img = cv2.resize(crop_image, dim, interpolation = cv2.INTER_AREA)\n",
    "            try:\n",
    "                Dict_images[Dict[int(line.split(\" \")[0])]].append(resized_img)\n",
    "            except KeyError:\n",
    "                pass"
   ],
   "metadata": {
    "id": "OHeuSRB-uTBg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "images = '/content/images/test'\n",
    "labels = '/content/labels/test'\n",
    "\n",
    "file_list = os.listdir(images)\n",
    "\n",
    "for name in tqdm(file_list):\n",
    "    tmp_list_class = []\n",
    "    image = cv2.imread(images+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
    "    with open(labels+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        lines = [line.rstrip('\\n') for line in f]\n",
    "        for line in lines:\n",
    "            x = int((float(line.split(\" \")[1])-(float(line.split(\" \")[3])/2)) * 770)\n",
    "            y = int((float(line.split(\" \")[2])-(float(line.split(\" \")[4])/2)) * 576)\n",
    "            w = int(float(line.split(\" \")[3]) * 770 + 5)\n",
    "            h = int(float(line.split(\" \")[4]) * 576 + 5)\n",
    "\n",
    "            crop_image = image[y:y+h, x:x+w]\n",
    "            tmp_list_class.append(int(line.split(\" \")[0]))\n",
    "            dim = (120, 120)\n",
    "            resized_img = cv2.resize(crop_image, dim, interpolation = cv2.INTER_AREA)\n",
    "            try:\n",
    "                Dict_images_test[Dict[int(line.split(\" \")[0])]].append(resized_img)\n",
    "            except KeyError:\n",
    "                pass"
   ],
   "metadata": {
    "id": "QvqnWl4_RAPg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def model_version1():\n",
    "    # autoencoder model\n",
    "    # encoder\n",
    "    input = Input(shape=(120, 120, 1))\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D(pool_size=(2, 2), padding='same', name=\"encoded\")(x)\n",
    "    #decoder\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=decoded)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in Dict_images.keys():\n",
    "    print(str(i))\n",
    "    x_train = np.array(Dict_images[str(i)])\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "    x_test = np.array(Dict_images_test[str(i)])\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "    print(x_train.shape, x_test.shape)\n",
    "\n",
    "    # autoencoder model\n",
    "    # encoder\n",
    "    input = Input(shape=(120, 120, 1))\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D(pool_size=(2, 2), padding='same', name=\"encoded\")(x)\n",
    "    #decoder\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    model = Model(inputs=input, outputs=decoded)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x_train, x_train, batch_size = 64, epochs = 50, validation_data=(x_test, x_test))\n",
    "\n",
    "    model.save(str(i)+\"_trajectory_autoencoder.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for i in Dict_images.keys():\n",
    "    colab_link = '/content/'+str(i)+'_trajectory_autoencoder.h5'\n",
    "    gdrive_link = \"/content/drive/My Drive/models_trajectory/\"\n",
    "    shutil.copy(colab_link, gdrive_link)"
   ],
   "metadata": {
    "id": "vxTHSJYd4Oxs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in Dict_images_test.keys():\n",
    "    str(i)\n",
    "    model.load_weights('/content/drive/MyDrive/models_trajectory/'+str(i)+'_trajectory_autoencoder.h5')\n",
    "\n",
    "    images = np.array(Dict_images_test[str(i)])\n",
    "    images = images.astype('float32') / 255.\n",
    "    images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)\n",
    "\n",
    "    decoded_images = model.predict(images)\n",
    "\n",
    "    number_of_images = list(range(0, images.shape[0]))\n",
    "    random_images = np.random.choice(number_of_images, size=2, replace=False)\n",
    "\n",
    "    examples = []\n",
    "    for i in random_images:\n",
    "        original = images[i] * 255\n",
    "        decoded_img = decoded_images[i] * 255\n",
    "        comparison = np.hstack([original, decoded_img])\n",
    "        examples.append(comparison)\n",
    "\n",
    "    comparsion_images = np.vstack(examples)\n",
    "    cv2_imshow(comparsion_images)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "nfo9PpFd2onu",
    "outputId": "2af309fe-391d-407b-b6ee-7faad7f42931",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for i in Dict_images.keys():\n",
    "    str(i)\n",
    "    model.load_weights('/content/drive/MyDrive/models_trajectory/'+str(i)+'_trajectory_autoencoder.h5')\n",
    "    encoder = Model(inputs=model.input, outputs=model.get_layer(\"encoded\").output)\n",
    "\n",
    "    images = np.array(Dict_images[str(i)])\n",
    "    images = images.astype('float32') / 255.\n",
    "    images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)\n",
    "\n",
    "    features = encoder.predict(images)\n",
    "    indexes = list(range(0, images.shape[0]))\n",
    "    data = {\"indexes\": indexes, \"images\": Dict_images[str(i)], \"features\": features}\n",
    "    np.save(str(i)+\"_trajectory_data.npy\", data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VyzoRT8vK7Iu",
    "outputId": "e98bfb8f-8650-47f8-97d8-de6d45b523af",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in Dict_images.keys():\n",
    "    colab_link = '/content/'+str(i)+'_trajectory_data.npy'\n",
    "    gdrive_link = \"/content/drive/My Drive/models_trajectory/\"\n",
    "    shutil.copy(colab_link, gdrive_link)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Os56u2lS81UO",
    "outputId": "1bf7655e-d24d-4c94-a6de-3e7733ac270d",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lõpp test sümbolid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!mkdir /content/images\n",
    "!mkdir /content/images/test_trajectory\n",
    "!mkdir /content/labels\n",
    "!mkdir /content/labels/test_trajectroy\n",
    "\n",
    "!unzip -q '/content/drive/My Drive/NATO/test_trajectory.zip' -d '/content/images/test_trajectory'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test_trajectory_l.zip' -d '/content/labels/test_trajectory'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Dict_images_test_trajectory = {key: [] for key in Dict.values()}\n",
    "images = '/content/images/test_trajectory'\n",
    "labels = '/content/labels/test_trajectory'\n",
    "\n",
    "file_list = os.listdir(images)\n",
    "\n",
    "for name in tqdm(file_list):\n",
    "    tmp_list_class = []\n",
    "    image = cv2.imread(images+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
    "    with open(labels+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        lines = [line.rstrip('\\n') for line in f]\n",
    "        for line in lines:\n",
    "            x = int((float(line.split(\" \")[1])-(float(line.split(\" \")[3])/2)) * 770)\n",
    "            y = int((float(line.split(\" \")[2])-(float(line.split(\" \")[4])/2)) * 576)\n",
    "            w = int(float(line.split(\" \")[3]) * 770 + 5)\n",
    "            h = int(float(line.split(\" \")[4]) * 576 + 5)\n",
    "\n",
    "            crop_image = image[y:y+h, x:x+w]\n",
    "            tmp_list_class.append(int(line.split(\" \")[0]))\n",
    "            dim = (120, 120)\n",
    "            resized_img = cv2.resize(crop_image, dim, interpolation = cv2.INTER_AREA)\n",
    "            try:\n",
    "                Dict_images_test_trajectory[Dict[int(line.split(\" \")[0])]].append(resized_img)\n",
    "            except KeyError:\n",
    "                pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = model_version1()\n",
    "\n",
    "symbol_valik = \"attack\"\n",
    "\n",
    "model.load_weights('/content/drive/MyDrive/models_trajectory/'+symbol_valik+'_trajectory_autoencoder.h5')\n",
    "encoder = Model(inputs=model.input, outputs=model.get_layer(\"encoded\").output)\n",
    "\n",
    "images = np.array(Dict_images_test_trajectory[symbol_valik])\n",
    "images = images.astype('float32') / 255.\n",
    "images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)\n",
    "\n",
    "predicted = encoder.predict(images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find similarity"
   ],
   "metadata": {
    "id": "3gukzbOhPpRw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "number_of_images = list(range(0, images.shape[0]))\n",
    "random_images = np.random.choice(number_of_images, size=3, replace=False)"
   ],
   "metadata": {
    "id": "1pCZITzjPme7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "load_data = np.load(\"/content/\"+symbol_valik+\"_trajectory_data.npy\", allow_pickle=True)\n",
    "load_features = load_data.item().get(\"features\")\n",
    "load_images = load_data.item().get(\"images\")\n",
    "features_reshape = load_features.reshape((-1, np.prod((load_features.shape[1:]))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN (Cosine)"
   ],
   "metadata": {
    "id": "RP1O9G3rDIia"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "knn_cosine = NearestNeighbors(n_neighbors=5, metric=\"cosine\")\n",
    "knn_cosine.fit(features_reshape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7pEQeVYFVNQ",
    "outputId": "5ea0214f-6430-4408-d98d-610e78230338",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_reshape = predicted.reshape((-1, np.prod((predicted.shape[1:]))))\n",
    "\n",
    "for i in random_images:\n",
    "    distances, indices = knn_cosine.kneighbors([predicted_reshape[i]])\n",
    "    results = [load_images[idx] for idx in indices.flatten()]\n",
    "    imgs = []\n",
    "    for index in results:\n",
    "        image = index.astype(\"uint8\")\n",
    "        image = np.dstack([image] * 3)\n",
    "        imgs.append(image)\n",
    "    query = (images[i] * 255).astype(\"uint8\")\n",
    "    print(\"Original\")\n",
    "    cv2_imshow(query)\n",
    "    montage = build_montages(imgs, (70, 70), (5, 1))[0]\n",
    "    print(\"Similar symbols\")\n",
    "    cv2_imshow(montage)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MvFCeCjyHbIt",
    "outputId": "0cc3b28f-ecec-467a-cdce-da10dd0e9c5a",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN (Euclidean)"
   ],
   "metadata": {
    "id": "vKEhHKEtW9Tz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "knn_euclidean = NearestNeighbors(n_neighbors=5, metric=\"euclidean\")\n",
    "knn_euclidean.fit(features_reshape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LwHjoM-YXAyV",
    "outputId": "913f128b-c955-476d-8cf8-7a1b990105df",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predicted_reshape = predicted.reshape((-1, np.prod((predicted.shape[1:]))))\n",
    "\n",
    "for i in random_images:\n",
    "    distances, indices = knn_euclidean.kneighbors([predicted_reshape[i]])\n",
    "    results = [load_images[idx] for idx in indices.flatten()]\n",
    "    imgs = []\n",
    "    for index in results:\n",
    "        image = index.astype(\"uint8\")\n",
    "        image = np.dstack([image] * 3)\n",
    "        imgs.append(image)\n",
    "    query = (images[i] * 255).astype(\"uint8\")\n",
    "    print(\"Original\")\n",
    "    cv2_imshow(query)\n",
    "    montage = build_montages(imgs, (70, 70), (5, 1))[0]\n",
    "    print(\"Similar symbols\")\n",
    "    cv2_imshow(montage)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rDUMWi44XE2f",
    "outputId": "3ba9f9b4-0ca0-43f6-e163-07959d68ff6b",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}