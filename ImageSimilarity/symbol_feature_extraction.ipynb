{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Data loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Reshape, UpSampling2D, Flatten, Dense, Lambda, BatchNormalization\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.losses import mse\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from scipy import ndimage\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from imutils import build_montages\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "from google.colab import drive\n",
    "\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir /content/images\n",
    "!mkdir /content/images/train\n",
    "!mkdir /content/images/test\n",
    "!mkdir /content/labels\n",
    "!mkdir /content/labels/train\n",
    "!mkdir /content/labels/test\n",
    "!mkdir /content/rotations\n",
    "!mkdir /content/rotations/train\n",
    "!mkdir /content/rotations/test"
   ],
   "metadata": {
    "id": "VOXBB-8MJPDJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip -q '/content/drive/My Drive/NATO/train2904.zip' -d '/content/images/train'\n",
    "!unzip -q '/content/drive/My Drive/NATO/train_l2904.zip' -d '/content/labels/train'\n",
    "!unzip -q '/content/drive/My Drive/NATO/train_r2904.zip' -d '/content/rotations/train'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test2904.zip' -d '/content/images/test'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test_l2904.zip' -d '/content/labels/test'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test_r2904.zip' -d '/content/rotations/test'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lNtsv2P_j9iT",
    "outputId": "1b35ec1f-b969-4bf8-a36c-9dfb6a5bfabb",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Dict = {0: 'advance_to_contact', 2: 'attack', 9: 'counterattack', 18: 'main_attack'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Dict_images = {key: [] for key in Dict.values()}\n",
    "Dict_images_test = {key: [] for key in Dict.values()}"
   ],
   "metadata": {
    "id": "J47qILT4j7m7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "images = '/content/images/train'\n",
    "labels = '/content/labels/train'\n",
    "rotations = '/content/rotations/train'\n",
    "\n",
    "file_list = os.listdir(images)\n",
    "\n",
    "for name in tqdm(file_list):\n",
    "    tmp_list_class = []\n",
    "    image = cv2.imread(images+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
    "    imageW = image.shape[1]\n",
    "    imageH = image.shape[0]\n",
    "    with open(labels+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        lines = [line.rstrip('\\n') for line in f]\n",
    "    with open(rotations+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        rots = [line.rstrip('\\n') for line in f]\n",
    "        for nr, line in enumerate(lines):\n",
    "            x = int((float(line.split(\" \")[1])-(float(line.split(\" \")[3])/2)) * imageW)\n",
    "            y = int((float(line.split(\" \")[2])-(float(line.split(\" \")[4])/2)) * imageH)\n",
    "            w = int(float(line.split(\" \")[3]) * imageW + 5)\n",
    "            h = int(float(line.split(\" \")[4]) * imageH + 5)\n",
    "\n",
    "            crop_image = image[y:y+h, x:x+w]\n",
    "            tmp_list_class.append(int(line.split(\" \")[0]))\n",
    "            crop_image = ndimage.rotate(crop_image, -int(rots[nr]), mode='constant', cval=255) ### rotation aspekt\n",
    "            dim = (80, 80)\n",
    "            resized_img = cv2.resize(crop_image, dim, interpolation = cv2.INTER_AREA)\n",
    "            binImg = img = np.where(resized_img <= 150, 0, 255)\n",
    "            try:\n",
    "                Dict_images[Dict[int(line.split(\" \")[0])]].append(binImg)\n",
    "            except KeyError:\n",
    "                pass"
   ],
   "metadata": {
    "id": "OHeuSRB-uTBg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "images = '/content/images/test'\n",
    "labels = '/content/labels/test'\n",
    "rotations = '/content/rotations/test'\n",
    "\n",
    "file_list = os.listdir(images)\n",
    "\n",
    "for name in tqdm(file_list):\n",
    "    tmp_list_class = []\n",
    "    image = cv2.imread(images+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
    "    with open(labels+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        lines = [line.rstrip('\\n') for line in f]\n",
    "    with open(rotations+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
    "        rots = [line.rstrip('\\n') for line in f]\n",
    "        for nr, line in enumerate(lines):\n",
    "            x = int((float(line.split(\" \")[1])-(float(line.split(\" \")[3])/2)) * 770)\n",
    "            y = int((float(line.split(\" \")[2])-(float(line.split(\" \")[4])/2)) * 576)\n",
    "            w = int(float(line.split(\" \")[3]) * 770 + 5)\n",
    "            h = int(float(line.split(\" \")[4]) * 576 + 5)\n",
    "\n",
    "            crop_image = image[y:y+h, x:x+w]\n",
    "            tmp_list_class.append(int(line.split(\" \")[0]))\n",
    "            crop_image = ndimage.rotate(crop_image, -int(rots[nr]), mode='constant', cval=255) ### rotation aspekt\n",
    "            dim = (80, 80)\n",
    "            resized_img = cv2.resize(crop_image, dim, interpolation = cv2.INTER_AREA)\n",
    "            binImg = img = np.where(resized_img <= 150, 0, 255)\n",
    "            try:\n",
    "                Dict_images_test[Dict[int(line.split(\" \")[0])]].append(binImg)\n",
    "            except KeyError:\n",
    "                pass"
   ],
   "metadata": {
    "id": "QvqnWl4_RAPg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Sampling(inputs):\n",
    "    mean, log_var = inputs\n",
    "    return K.random_normal(tf.shape(mean)) * K.exp(log_var / 2) + mean\n",
    "\n",
    "def model_version12():\n",
    "    # autoencoder model\n",
    "    beta_value = 50\n",
    "    # encoder\n",
    "    input = Input(shape=(80, 80, 1))\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(input)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    codings_mean = keras.layers.Dense(10, name=\"encoder_mean\")(x)\n",
    "    codings_log_var = keras.layers.Dense(10, name=\"encoder_log_var\")(x)\n",
    "    codings = Lambda(Sampling, name=\"encoder_output\")([codings_mean, codings_log_var])\n",
    "    variational_encoder = keras.models.Model(inputs=[input], outputs=[codings_mean, codings_log_var, codings], name=\"encoder\")\n",
    "\n",
    "    #decoder\n",
    "    decoder_inputs = keras.layers.Input(shape=(10))\n",
    "    z = Dense(256, activation='relu')(decoder_inputs)\n",
    "    z = Dense(256, activation='relu')(z)\n",
    "    z = Dense(5*5*32, activation='relu')(z)\n",
    "    z = Reshape((5, 5, 32))(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    output = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(z)\n",
    "    variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[output], name=\"decoder\")\n",
    "\n",
    "    _, _, codings = variational_encoder(input)\n",
    "    reconstructions = variational_decoder(codings)\n",
    "    variational_ae = keras.models.Model(inputs=[input], outputs=[reconstructions], name=\"autoencoder\")\n",
    "\n",
    "    reconstruction_loss_factor = 1000\n",
    "    reconstruction_loss = mse(K.flatten(input), K.flatten(reconstructions))\n",
    "    reconstruction_loss *= 80 * 80 * 1\n",
    "    kl_loss = -0.5 * beta_value * K.sum(1 + codings_log_var - K.square(codings_mean) - K.exp(codings_log_var), axis=1)\n",
    "    vae_loss = K.mean(reconstruction_loss_factor * reconstruction_loss + kl_loss)\n",
    "    variational_ae.add_loss(vae_loss)\n",
    "\n",
    "    variational_ae.add_metric(kl_loss, name=\"kl_loss\")\n",
    "    variational_ae.add_metric(reconstruction_loss, name=\"reconstruction_loss\")\n",
    "\n",
    "    return variational_ae"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in Dict_images.keys():\n",
    "    print(str(i))\n",
    "    x_train = np.array(Dict_images[str(i)])\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "    x_test = np.array(Dict_images_test[str(i)])\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "\n",
    "    print(x_train.shape, x_test.shape)\n",
    "\n",
    "    # earlyStopping = EarlyStopping(monitor='val_reconstruction_loss', start_from_epoch=50, patience=20, restore_best_weights=True, verbose=1, mode=\"min\")\n",
    "\n",
    "    model = model_version12()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam')\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x_train, x_train, batch_size = 128, epochs = 200, validation_data=(x_test, x_test))\n",
    "\n",
    "    model.save(str(i)+\"_autoencoder_model12_b50_10.h5\")\n",
    "\n",
    "    colab_link = '/content/'+str(i)+'_autoencoder_model12_b50_10.h5'\n",
    "    gdrive_link = \"/content/drive/My Drive/models_trajectory_final/\"\n",
    "    shutil.copy(colab_link, gdrive_link)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for i in Dict_images_test.keys():\n",
    "    str(i)\n",
    "    model = model_version12()\n",
    "    model.load_weights('/content/drive/MyDrive/models_trajectory_final/'+str(i)+'_autoencoder_model12_b3_10.h5')\n",
    "\n",
    "    images = np.array(Dict_images_test[str(i)])\n",
    "    images = images.astype('float32') / 255.\n",
    "    images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)\n",
    "\n",
    "    decoded_images = model.predict(images)\n",
    "\n",
    "    number_of_images = list(range(0, images.shape[0]))\n",
    "    random_images = np.random.choice(number_of_images, size=10, replace=False)\n",
    "\n",
    "    examples = []\n",
    "    for j in random_images:\n",
    "        original = images[j] * 255\n",
    "        decoded_img = decoded_images[j] * 255\n",
    "        comparison = np.hstack([original, decoded_img])\n",
    "        examples.append(comparison)\n",
    "\n",
    "    comparison_images = np.vstack(examples)\n",
    "    cv2_imshow(comparison_images)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "id": "nfo9PpFd2onu",
    "outputId": "2af309fe-391d-407b-b6ee-7faad7f42931",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}