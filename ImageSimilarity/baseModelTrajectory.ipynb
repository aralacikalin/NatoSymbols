{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, BatchNormalization, Conv2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras import metrics\n",
        "\n",
        "from sklearn import metrics as sklearn_metrics\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "wATlZhbBrpvw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7acfLQU4rXNi"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/images\n",
        "!mkdir /content/images/train\n",
        "!mkdir /content/labels\n",
        "!mkdir /content/labels/train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "MxVhXmmFwFKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/drive/My Drive/NATO/train_base.zip' -d '/content/images/train'\n",
        "!unzip -q '/content/drive/My Drive/NATO/train_base_l.zip' -d '/content/labels/train'"
      ],
      "metadata": {
        "id": "peZWvNeXr-Hw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'otse_k': 4362, 'otse_l': 4349, 'parem_n': 5141, 'parem_y': 5103, 'vasak_n': 5173, 'vasak_y': 5162}"
      ],
      "metadata": {
        "id": "7eoBp0QTuDv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CNNModel():\n",
        "    classes = 6\n",
        "\n",
        "    input = Input(shape=(80, 80, 1))\n",
        "    x = Conv2D(64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation='relu')(input)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation='relu')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2), padding = 'same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input, outputs=x)\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "EPbP9ZHkrx2L"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = '/content/images/train'\n",
        "labels = '/content/labels/train'\n",
        "\n",
        "x_ = []\n",
        "y_ = []\n",
        "\n",
        "file_list = os.listdir(images)\n",
        "\n",
        "for name in tqdm(file_list):\n",
        "    image = cv2.imread(images+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
        "    with open(labels+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
        "        lines = [line.rstrip('\\n') for line in f]\n",
        "        for line in lines:\n",
        "            l = int(line.split(\" \")[0])\n",
        "            x = int((float(line.split(\" \")[1])-(float(line.split(\" \")[3])/2)) * 770)\n",
        "            y = int((float(line.split(\" \")[2])-(float(line.split(\" \")[4])/2)) * 578)\n",
        "            w = int(float(line.split(\" \")[3]) * 770 + 5)\n",
        "            h = int(float(line.split(\" \")[4]) * 576 + 5)\n",
        "\n",
        "            crop_image = image[y:y+h, x:x+w]\n",
        "            dim = (80, 80)\n",
        "            resized_img = cv2.resize(crop_image, dim, interpolation = cv2.INTER_AREA)\n",
        "            x_.append(resized_img)\n",
        "            y_.append(l)"
      ],
      "metadata": {
        "id": "ClgB58CXt-Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_categorical = to_categorical(y_, 6)\n",
        "\n",
        "x_train = np.array(x_[0:])\n",
        "y_train = np.array(y_categorical)\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "\n",
        "model = CNNModel()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=[metrics.categorical_accuracy])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size = 64, epochs = 50)"
      ],
      "metadata": {
        "id": "vdLTC1xlr1MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"base_pose_model_1803_5.h5\")"
      ],
      "metadata": {
        "id": "iByoZ6LRsVCI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/images\n",
        "!mkdir /content/images/test\n",
        "!mkdir /content/labels\n",
        "!mkdir /content/labels/test"
      ],
      "metadata": {
        "id": "P_735g575I81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q '/content/drive/My Drive/NATO/test_base.zip' -d '/content/images/test'\n",
        "!unzip -q '/content/drive/My Drive/NATO/test_base_l.zip' -d '/content/labels/test'"
      ],
      "metadata": {
        "id": "O3Lsi1Ri5Iac"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'otse_k': 997, 'otse_l': 987, 'parem_n': 1013, 'parem_y': 1024, 'vasak_n': 1051, 'vasak_y': 1009}"
      ],
      "metadata": {
        "id": "TlgJfBAgGy2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images_test = '/content/images/test'\n",
        "labels_test = '/content/labels/test'\n",
        "\n",
        "file_list = os.listdir(images_test)\n",
        "model = CNNModel()\n",
        "\n",
        "actual = []\n",
        "predicted = []\n",
        "\n",
        "for name in tqdm(file_list):\n",
        "    image = cv2.imread(images_test+\"/\"+name, cv2.IMREAD_GRAYSCALE)\n",
        "    with open(labels_test+\"/\"+str(name).split(\".\")[0]+\".txt\") as f:\n",
        "        lines = [line.rstrip('\\n') for line in f]\n",
        "        for line in lines:\n",
        "            actual.append(int(line.split(\" \")[0]))\n",
        "\n",
        "            x = int((float(line.split(\" \")[1])-(float(line.split(\" \")[3])/2)) * 770)\n",
        "            y = int((float(line.split(\" \")[2])-(float(line.split(\" \")[4])/2)) * 578)\n",
        "            w = int(float(line.split(\" \")[3]) * 770 + 5)\n",
        "            h = int(float(line.split(\" \")[4]) * 576 + 5)\n",
        "\n",
        "            # Symbol\n",
        "            crop_image = image[y:y+h, x:x+w]\n",
        "            dim = (80, 80)\n",
        "            resized_img = cv2.resize(crop_image, dim, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "            ## Predict\n",
        "            reshaped_img = resized_img.reshape(1, 80, 80)\n",
        "            model.load_weights('/content/base_pose_model_1803.h5')\n",
        "            predicted_label = model.predict(reshaped_img, verbose=0)\n",
        "            predicted.append(np.argmax(predicted_label))"
      ],
      "metadata": {
        "id": "WUej-_N85Z95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix = sklearn_metrics.confusion_matrix(actual, predicted)\n",
        "cm_display = sklearn_metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['otse_kitsas', 'otse_lai', 'parem_45', 'parem_90', 'vasak_45', 'vasak_90'])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "cm_display.plot(ax = ax)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(actual, predicted))"
      ],
      "metadata": {
        "id": "uec38CaS-rzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}