{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "670U7jMTQwvQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, Reshape, UpSampling2D, Flatten, Dense, Lambda, BatchNormalization\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.losses import mse\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "from google.colab import drive\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir /content/images\n",
    "!mkdir /content/images2\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip -q '/content/drive/My Drive/NATO/chooseFrom.zip' -d '/content/images'\n",
    "!unzip -q '/content/drive/My Drive/NATO/test_images.zip' -d '/content/images2'"
   ],
   "metadata": {
    "id": "Me7Tfm-cRTu9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Dict = {0: 'advance_to_contact', 2: 'attack', 9: 'counterattack', 18: 'main_attack'}\n",
    "# Dict = {0: 'otse_k', 1: 'otse_l', 2: 'parem_n', 3: 'parem_y', 4: 'vasak_n', 5: 'vasak_y'}\n",
    "Dict_images = {key: [] for key in Dict.values()}"
   ],
   "metadata": {
    "id": "6KV_fbu5RPSU"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def cut_excess_white(symbol, excess_str = 120):\n",
    "    symbol = symbol[np.argwhere(np.amin(symbol,axis=1) < excess_str)[0][0]:np.argwhere(np.amin(symbol,axis=1) < excess_str)[-1][0],:]\n",
    "    symbol = symbol[:,np.argwhere(np.amin(symbol,axis=0) < excess_str)[0][0]:np.argwhere(np.amin(symbol,axis=0) < excess_str)[-1][0]]\n",
    "    return symbol"
   ],
   "metadata": {
    "id": "4PbsTE4qTVhw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# data = '/content/images2'\n",
    "# file_list=os.listdir(data)\n",
    "\n",
    "# symbols_regex = '([a-zA-Z_ ]*)\\d*.*'\n",
    "# for filename in tqdm(file_list):\n",
    "#    img = cv2.imread(data+\"/\"+filename, 0)\n",
    "#    img[img <= 100] = 0\n",
    "#    img[img > 100] = 255\n",
    "#    img = cut_excess_white(img)\n",
    "#    key = re.findall(symbols_regex, filename)[0]\n",
    "#    Dict_images[key].append(img)"
   ],
   "metadata": {
    "id": "7quRToxoRgfC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = '/content/images'\n",
    "file_list=os.listdir(data)\n",
    "\n",
    "dir_regex = '([a-zA-Z_ ]*)\\d*.*'\n",
    "symbols_regex = '([a-zA-Z_ ]*)\\d*.*'\n",
    "for dir in file_list:\n",
    "    for filename in tqdm(os.listdir(data+\"/\"+dir)):\n",
    "        img = cv2.imread(data+\"/\"+dir+\"/\"+filename, 0)\n",
    "        img[img <= 100] = 0\n",
    "        img[img > 100] = 255\n",
    "        img = cut_excess_white(img)\n",
    "        key = re.findall(symbols_regex, dir)[0]\n",
    "        key2 = re.findall(symbols_regex, filename)[0]\n",
    "        Dict_images[key].append([img, str(key2)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Dict_images_all = {key: [] for key in Dict.values()}"
   ],
   "metadata": {
    "id": "Guvj7gRpgUhy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def rotate_images(image, symbol):\n",
    "    for degree in range(0, 1, 5):\n",
    "        rotation_angle = degree\n",
    "        img = ndimage.rotate(image, rotation_angle, mode='constant', cval=255)\n",
    "        dim = (80, 80)\n",
    "        resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "        binImg = np.where(resized_img <= 150, 0, 255)\n",
    "        Dict_images_all[symbol].append(binImg)"
   ],
   "metadata": {
    "id": "-fCiKHvfXL0N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for i in Dict_images.keys():\n",
    "    for img in tqdm(Dict_images[str(i)]):\n",
    "        rotate_images(img[0], str(i))"
   ],
   "metadata": {
    "id": "-ZRg04h9YZBN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def Sampling(inputs):\n",
    "    mean, log_var = inputs\n",
    "    return K.random_normal(tf.shape(mean)) * K.exp(log_var / 2) + mean\n",
    "\n",
    "def model_version12():\n",
    "    # autoencoder model\n",
    "    beta_value = 50\n",
    "    # encoder\n",
    "    input = Input(shape=(80, 80, 1))\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(input)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    codings_mean = keras.layers.Dense(10, name=\"encoder_mean\")(x)\n",
    "    codings_log_var = keras.layers.Dense(10, name=\"encoder_log_var\")(x)\n",
    "    codings = Lambda(Sampling, name=\"encoder_output\")([codings_mean, codings_log_var])\n",
    "    variational_encoder = keras.models.Model(inputs=[input], outputs=[codings_mean, codings_log_var, codings], name=\"encoder\")\n",
    "\n",
    "    #decoder\n",
    "    decoder_inputs = keras.layers.Input(shape=(10))\n",
    "    z = Dense(256, activation='relu')(decoder_inputs)\n",
    "    z = Dense(256, activation='relu')(z)\n",
    "    z = Dense(5*5*32, activation='relu')(z)\n",
    "    z = Reshape((5, 5, 32))(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    z = Conv2DTranspose(32, (3, 3), strides=(2, 2), activation='relu', padding='same')(z)\n",
    "    output = Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(z)\n",
    "    variational_decoder = keras.models.Model(inputs=[decoder_inputs], outputs=[output], name=\"decoder\")\n",
    "\n",
    "    _, _, codings = variational_encoder(input)\n",
    "    reconstructions = variational_decoder(codings)\n",
    "    variational_ae = keras.models.Model(inputs=[input], outputs=[reconstructions], name=\"autoencoder\")\n",
    "\n",
    "    reconstruction_loss_factor = 1000\n",
    "    reconstruction_loss = mse(K.flatten(input), K.flatten(reconstructions))\n",
    "    reconstruction_loss *= 80 * 80 * 1\n",
    "    kl_loss = -0.5 * beta_value * K.sum(1 + codings_log_var - K.square(codings_mean) - K.exp(codings_log_var), axis=1)\n",
    "    vae_loss = K.mean(reconstruction_loss_factor * reconstruction_loss + kl_loss)\n",
    "    variational_ae.add_loss(vae_loss)\n",
    "\n",
    "    variational_ae.add_metric(kl_loss, name=\"kl_loss\")\n",
    "    variational_ae.add_metric(reconstruction_loss, name=\"reconstruction_loss\")\n",
    "\n",
    "    return variational_ae"
   ],
   "metadata": {
    "id": "gk74rOc8oUeT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = model_version12()\n",
    "\n",
    "for i in Dict_images_all.keys():\n",
    "    print(str(i))\n",
    "    model.load_weights('/content/drive/MyDrive/models_trajectory_final/'+str(i)+'_autoencoder_model12_b50_10.h5')\n",
    "    encoder = Model(inputs=model.input, outputs=model.get_layer(\"encoder\").output)\n",
    "\n",
    "    extra_labels = []\n",
    "    for img in Dict_images[str(i)]:\n",
    "        extra_labels.append(img[1])\n",
    "\n",
    "\n",
    "    images = np.array(Dict_images_all[str(i)])\n",
    "    images = images.astype('float32') / 255.\n",
    "    images = images.reshape(images.shape[0], images.shape[1], images.shape[2], 1)\n",
    "\n",
    "    _, _, features = encoder.predict(images)\n",
    "    data = {\"images\": Dict_images_all[str(i)], \"features\": features, \"extra_label\": extra_labels}\n",
    "    np.save(str(i)+\"_data_model12_b50_10.npy\", data)\n",
    "\n",
    "    colab_link = '/content/'+str(i)+'_data_model12_b50_10.npy'\n",
    "    gdrive_link = \"/content/drive/My Drive/npy_final/\"\n",
    "    shutil.copy(colab_link, gdrive_link)"
   ],
   "metadata": {
    "id": "5o60_V7fnxko"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}